# Proyecto 3 - MLOps (Fase Local)

Este proyecto implementa una arquitectura bÃ¡sica de MLOps de manera local para el procesamiento de datos, entrenamiento y predicciÃ³n de un modelo de clasificaciÃ³n, utilizando FastAPI y almacenamiento en MySQL.

---

## ğŸ“ Estructura del Proyecto

```text
Proyecto_3/
â”‚
â”œâ”€â”€ app_back/                      # Backend con FastAPI
â”‚   â””â”€â”€ main.py                    # Endpoints de carga, procesamiento, entrenamiento y predicciÃ³n
â”‚
â”œâ”€â”€ app_front/                     # Interfaz Streamlit (opcional)
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ connections/                   # ConfiguraciÃ³n de conexiÃ³n a MySQL (RAW y CLEAN)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ mysql_connections.py
â”‚
â”œâ”€â”€ dags/                          # Scripts de procesamiento, carga y entrenamiento (para Airflow)
â”‚   â”œâ”€â”€ carga_datos.py             # Inserta datos crudos en RAW
â”‚   â”œâ”€â”€ preprocesar_datos.py       # Procesa datos y los guarda por lotes en CLEAN
â”‚   â””â”€â”€ train_model.py             # Entrena modelos por lote, guarda mÃ©tricas y el mejor modelo
â”‚
â”œâ”€â”€ data/Diabetes/                 # Dataset original
â”‚   â””â”€â”€ Diabetes.csv
â”‚
â”œâ”€â”€ mlflow/                        # ConfiguraciÃ³n de MLflow
â”‚   â”œâ”€â”€ dockerfile_mlflow          # Dockerfile para servidor MLflow
â”‚   â””â”€â”€ requirements_mlflow.txt    # Requerimientos especÃ­ficos de MLflow
â”‚
â”œâ”€â”€ minio/                         # Carpeta montada por MinIO para almacenamiento S3
â”‚   â””â”€â”€ (se llena en tiempo de ejecuciÃ³n)
â”‚
â”œâ”€â”€ models/                        # Modelos serializados entrenados
â”‚   â”œâ”€â”€ modelo_entrenado_batch1.pkl
â”‚   â”œâ”€â”€ modelo_entrenado_batch2.pkl
â”‚   â”œâ”€â”€ modelo_entrenado_batch3.pkl
â”‚   â”œâ”€â”€ modelo_entrenado_batch4.pkl
â”‚   â”œâ”€â”€ modelo_entrenado_batch5.pkl
â”‚   â”œâ”€â”€ modelo_entrenado_batch6.pkl
â”‚   â””â”€â”€ modelo_entrenado_final.pkl  # Mejor modelo segÃºn mÃ©trica definida
â”‚
â”œâ”€â”€ imagenes/                      # Recursos grÃ¡ficos
â”‚   â”œâ”€â”€ arquitectura.png
â”‚   â””â”€â”€ Front_Streamlit.png
â”‚   â””â”€â”€ Airflow.png
â”‚   â””â”€â”€ MlFlow.png
â”‚   â””â”€â”€ Minio.png
â”‚   â””â”€â”€ Arquitectura del proyecto.png
â”‚
â”‚
â”œâ”€â”€ logs/                          # Logs generados por las ejecuciones de Airflow o el sistema
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ plugins/                       # (Opcional) Plugins de Airflow si se usan
â”‚
â”œâ”€â”€ docker-compose.yml            # OrquestaciÃ³n de servicios: Airflow, MLflow, MinIO, MySQL, etc.
â”œâ”€â”€ dockerfile                    # Dockerfile general
â”œâ”€â”€ requirements.txt              # Dependencias globales del proyecto
â””â”€â”€ .README.md                     # DocumentaciÃ³n del proyecto

```

## âœ… Funcionalidad Actual


- **Carga de datos**  
  Inserta datos crudos en la tabla `initial_data` del esquema `raw_data`.

- **Preprocesamiento**  
  Limpia los datos, elimina columnas irrelevantes, transforma variables categÃ³ricas y divide el dataset en conjuntos de `entrenamiento`, `validaciÃ³n` y `prueba`. La siguiente funciÃ³n fue definida para que se tomen los datasets de entrenamiento, validaciÃ³n y prueba generados tras el preprocesamiento, y los almacena en la base de datos `CLEAN_DATA` en tres tablas: `train_data`, `val_data` y `test_data`.

  El dataset de entrenamiento se divide en lotes (`batches`) del tamaÃ±o especificado (por defecto 15,000 registros) para permitir un procesamiento mÃ¡s controlado. Cada lote es almacenado en la tabla `train_data` con una columna adicional llamada `batch_id` que indica a quÃ© lote pertenece cada registro.

  #### CÃ³digo:

  ```bash
  def almacenar_en_clean_data(df_train, df_val, df_test, batch_size=15000, random_state=42):
      try:
          df_train = df_train.sample(frac=1, random_state=random_state).reset_index(drop=True)
          total_batches = ceil(len(df_train) / batch_size)

          for batch_number in range(1, total_batches + 1):
              start = (batch_number - 1) * batch_size
              end = batch_number * batch_size
              df_batch = df_train.iloc[start:end].copy()

              if df_batch.empty:
                  continue

              df_batch["batch_id"] = batch_number
              crear_y_reemplazar_si_existe(df_batch, "train_data", cleandatadb_engine)

          crear_y_reemplazar_si_existe(df_val, "val_data", cleandatadb_engine)
          crear_y_reemplazar_si_existe(df_test, "test_data", cleandatadb_engine)

          print("Carga en CLEAN_DATA completada.")
          return total_batches

      except Exception as e:
          print(f"Error al almacenar en CLEAN_DATA: {e}")
          raise e
  ```
- **Entrenamiento del modelo**  
  Entrena mÃºltiples modelos `RandomForestClassifier` (uno por cada batch) usando `Pipeline` de `scikit-learn`, guarda cada uno como `modelo_entrenado_batch{n}.pkl`, registra sus mÃ©tricas (`accuracy`, `precision`, `recall`, `f1-score`) en la tabla `clean_data.experiments` y selecciona el mejor modelo basado en `val_f1`, copiÃ¡ndolo como `modelo_entrenado_final.pkl`.

- **PredicciÃ³n vÃ­a API**  
  Utiliza el modelo `modelo_entrenado_final.pkl` para predecir nuevas muestras y guarda las predicciones con sus probabilidades en `raw_data.predictions`.

- **Interfaz grÃ¡fica con Streamlit**  
  Permite a los usuarios realizar predicciones desde un formulario web amigable, que se comunica con la API FastAPI para enviar datos y mostrar resultados.

  ![Interfaz Streamlit](imagenes/Front_Streamlit.png)

- **API REST con FastAPI**  
  Permite ejecutar cada etapa del flujo mediante endpoints:

| Endpoint        | AcciÃ³n                                                   |
|----------------|----------------------------------------------------------|
| `/download`     | Descarga el dataset e inserta en `raw_data.initial_data` |
| `/clean`        | Preprocesa y divide los datos, luego guarda por lotes    |
| `/train`        | Entrena todos los modelos por lote y selecciona el mejor |
| `/predict`      | Realiza predicciones usando el mejor modelo entrenado    |

- **Airflow**  

Airflow se encarga de orquestar las tareas del flujo ETL y entrenamiento. Se ha implementado con Docker Compose y se compone de los siguientes DAGs:

- `cargar_datos`: descarga un dataset CSV desde Google Drive y lo inserta en MySQL en la Base `ROW_DATA`.
- `preprocesar_datos`: limpia y transforma los datos, y los guarda en la base `CLEAN_DATA`.
- `train_model`: entrena varios modelos por lotes y selecciona el mejor usando `RandomForest`.

  **Configuraciones destacadas**:
- Los DAGs se ejecutan en orden gracias a `ExternalTaskSensor`.
- Se utilizan `PythonOperator` para ejecutar funciones personalizadas.
- Airflow usa MySQL como backend.
- El servicio estÃ¡ expuesto en el puerto `8080`.

  ![Airflow](imagenes\Ariflow.png)

- **Minio**  
MinIO actÃºa como almacenamiento tipo S3 para MLflow.

- Se expone la consola de MinIO en el puerto `8083`.
- Se creÃ³ un bucket llamado `mlflows3`.
- MLflow puede subir automÃ¡ticamente modelos `.pkl` y archivos al bucket.
- El servicio estÃ¡ expuesto en el puerto `8083`.

  ![Minio](imagenes\minio.png)

- **MlFlow**  

MLflow gestiona el tracking de los experimentos y almacenamiento de modelos. Se configurÃ³ de la siguiente forma:

- Usando `mysql` como `backend-store-uri` para guardar metadata de experimentos.
- Usando `MinIO` como almacenamiento de artefactos (`--default-artifact-root s3://mlflows3`).
- Se configurÃ³ un contenedor `mlflow_server` en Docker Compose.
- El servicio estÃ¡ expuesto en el puerto `8084`.
- Entra al contenedor de MySQL y ya dentro de la consola de MySQL:

```bash

docker exec -it mysql mysql -u root
contraseÃ±a: 
CREATE DATABASE IF NOT EXISTS mlflow;
EXIT;
```
- Nota: Aun esta pendiente configurar para que los experimentos que se realicen con el DAG de entrenamiento almacene los resultados como el modelo. 

  ![MlFlow](imagenes\mlflow.png)

---

## ğŸ§° Requisitos y Puesta en Marcha

Sigue estos pasos para ejecutar el proyecto localmente:

```bash
# 1. Clonar el repositorio
git clone git@github.com:JohnSanchez27/MLOPS_Proyectos_3.git
cd MLOPS_Proyectos_3
```