# Proyecto 3 - MLOps (Fase Local)

Este proyecto implementa una soluciÃ³n completa de MLOps que automatiza el proceso de entrenamiento, despliegue y consumo de un modelo de machine learning para predecir la probabilidad de que un paciente sea readmitido en un hospital. Utiliza un enfoque modular basado en contenedores con Docker y herramientas modernas como Apache Airflow, MLflow, MinIO, FastAPI y Streamlit.

  - **CaracterÃ­sticas principales**

        - AutomatizaciÃ³n del flujo de trabajo de datos con Airflow, desde la carga hasta el entrenamiento por lotes.
        - Entrenamiento de modelos por batch y selecciÃ³n automÃ¡tica del mejor modelo con mÃ©tricas como F1-score.
        - Registro y versionado de modelos en MLflow y almacenamiento de artefactos en MinIO como backend S3.
        - API REST construida con FastAPI que permite servir el modelo en producciÃ³n.
        - Interfaz de usuario interactiva desarrollada con Streamlit para simular casos de pacientes y consumir el modelo.
        - Persistencia de predicciones en base de datos MySQL para trazabilidad y anÃ¡lisis posterior.
        - ContenerizaciÃ³n de todos los servicios mediante Docker Compose para fÃ¡cil orquestaciÃ³n y despliegue local.

---

## ğŸ“ Estructura del Proyecto

```text
Proyecto_3/
â”‚
â”œâ”€â”€ app_back/                              # Backend con FastAPI
â”‚   â”œâ”€â”€ main.py                            # Endpoints de predicciÃ³n conectados a MLflow y MySQL
â”‚   â”œâ”€â”€ dockerfile_api.py                  # Dockerfile de la API FastAPI
â”‚   â””â”€â”€ requirements_api.txt               # Dependencias de FastAPI
â”‚
â”œâ”€â”€ app_front/                             # Interfaz de usuario con Streamlit
â”‚   â”œâ”€â”€ app.py                             # App de Streamlit para ingresar datos y consumir la API
â”‚   â”œâ”€â”€ dockerfile_app.py                  # Dockerfile para la interfaz de usuario
â”‚   â””â”€â”€ requirements_app.txt               # Dependencias de Streamlit
â”‚
â”œâ”€â”€ connections/                           # ConfiguraciÃ³n de conexiÃ³n a bases de datos MySQL
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ mysql_connections.py
â”‚
â”œâ”€â”€ dags/                                  # Scripts usados por Apache Airflow
â”‚   â”œâ”€â”€ carga_datos.py                     # Inserta datos crudos en base RAW
â”‚   â”œâ”€â”€ preprocesar_datos.py               # Procesa los datos y los guarda por lotes en CLEAN
â”‚   â””â”€â”€ train_model.py                     # Entrena modelos, guarda mÃ©tricas, y registra el mejor en MLflow
â”‚
â”œâ”€â”€ data/Diabetes/                         # Dataset original
â”‚   â””â”€â”€ Diabetes.csv
â”‚
â”œâ”€â”€ mlflow/                                # ConfiguraciÃ³n del servidor MLflow
â”‚   â”œâ”€â”€ dockerfile_mlflow                  # Dockerfile para MLflow
â”‚   â”œâ”€â”€ init.sql                           # Script de inicializaciÃ³n de base de datos para MLflow
â”‚   â””â”€â”€ requirements_mlflow.txt            # Requerimientos especÃ­ficos para MLflow
â”‚
â”œâ”€â”€ minio/                                 # Carpeta montada por MinIO para almacenar artefactos de MLflow
â”‚   â””â”€â”€ (se llena en tiempo de ejecuciÃ³n)
â”‚
â”œâ”€â”€ models/                                # Modelos entrenados y serializados
â”‚   â”œâ”€â”€ modelo_entrenado_batch1.pkl
â”‚   â”œâ”€â”€ modelo_entrenado_batch2.pkl
â”‚   â”œâ”€â”€ modelo_entrenado_batch3.pkl
â”‚   â”œâ”€â”€ modelo_entrenado_batch4.pkl
â”‚   â”œâ”€â”€ modelo_entrenado_batch5.pkl
â”‚   â”œâ”€â”€ modelo_entrenado_batch6.pkl
â”‚   â””â”€â”€ modelo_entrenado_final.pkl         # Mejor modelo identificado y registrado en MLflow
â”‚
â”œâ”€â”€ imagenes/                              # Recursos grÃ¡ficos para documentaciÃ³n
â”‚   â”œâ”€â”€ arquitectura.png
â”‚   â”œâ”€â”€ Front_Streamlit.png
â”‚   â”œâ”€â”€ Airflow.png
â”‚   â”œâ”€â”€ MlFlow.png
â”‚   â”œâ”€â”€ Minio.png
â”‚   â””â”€â”€ Arquitectura del proyecto.png
â”‚
â”œâ”€â”€ logs/                                  # Logs generados por Airflow y el sistema
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ plugins/                               # (Opcional) Plugins de Airflow si se utilizan
â”‚
â”œâ”€â”€ docker-compose.yml                     # OrquestaciÃ³n de servicios: Airflow, MLflow, MinIO, MySQL, etc.
â”œâ”€â”€ dockerfile                             # Dockerfile base del entorno
â”œâ”€â”€ requirements.txt                       # Dependencias globales del proyecto
â””â”€â”€ README.md                              # DocumentaciÃ³n del proyecto

```

## âœ… Funcionalidad Actual


- **Carga de datos**  
  La etapa de carga de datos del proyecto se encarga de descargar automÃ¡ticamente el conjunto de datos original desde una URL externa (especÃ­ficamente desde Google Drive) y almacenarlo en la base de datos RAW_DATA. El archivo solo se descarga si no existe previamente en el directorio local ./data/Diabetes, y se valida que no estÃ© vacÃ­o antes de procesarlo. Si las bases de datos RAW_DATA y CLEAN_DATA no existen, son creadas automÃ¡ticamente mediante SQLAlchemy. Posteriormente, los datos se insertan en la tabla initial_data del esquema RAW_DATA. Si la tabla no existe, se crea con base en la estructura del archivo CSV; si ya existe, su contenido se limpia antes de insertar los nuevos registros. Todo este flujo es gestionado por dos DAGs de Airflow: uno que verifica y crea las bases de datos (crear_bases_si_no_existen) y otro que realiza la descarga e inserciÃ³n del archivo (cargar_datos). Esto garantiza un proceso de ingesta robusto, automatizado y preparado para actualizaciones diarias.

- **Preprocesamiento**

  La etapa de preprocesamiento transforma los datos crudos almacenados en la tabla initial_data de la base RAW_DATA en un conjunto de datos limpio, estructurado y dividido en subconjuntos para entrenamiento, validaciÃ³n y prueba. Este proceso incluye la eliminaciÃ³n de columnas irrelevantes o con muchos valores nulos, la imputaciÃ³n de valores faltantes con la moda de cada categorÃ­a, el reemplazo de valores inconsistentes, la transformaciÃ³n de edades de rangos a valores numÃ©ricos y la recodificaciÃ³n de variables categÃ³ricas como tipo de admisiÃ³n, alta y fuente de ingreso. AdemÃ¡s, se eliminan registros con gÃ©nero no vÃ¡lido y columnas identificadoras como encounter_id y patient_nbr. Luego, los datos se dividen usando train_test_split y se almacenan en la base CLEAN_DATA en tres tablas: train_data, val_data y test_data. La tabla train_data se divide en lotes identificados con una columna batch_id para permitir un entrenamiento por etapas. Todo este flujo es orquestado por el DAG de Airflow preprocesar_datos, que ejecuta automÃ¡ticamente estas tareas al ser invocado

  #### CÃ³digo:

  ```bash
  def almacenar_en_clean_data(df_train, df_val, df_test, batch_size=15000, random_state=42):
      try:
          df_train = df_train.sample(frac=1, random_state=random_state).reset_index(drop=True)
          total_batches = ceil(len(df_train) / batch_size)

          for batch_number in range(1, total_batches + 1):
              start = (batch_number - 1) * batch_size
              end = batch_number * batch_size
              df_batch = df_train.iloc[start:end].copy()

              if df_batch.empty:
                  continue

              df_batch["batch_id"] = batch_number
              crear_y_reemplazar_si_existe(df_batch, "train_data", cleandatadb_engine)

          crear_y_reemplazar_si_existe(df_val, "val_data", cleandatadb_engine)
          crear_y_reemplazar_si_existe(df_test, "test_data", cleandatadb_engine)

          print("Carga en CLEAN_DATA completada.")
          return total_batches

      except Exception as e:
          print(f"Error al almacenar en CLEAN_DATA: {e}")
          raise e
  ```
- **Entrenamiento del modelo** 

  La etapa de entrenamiento se encarga de construir modelos de predicciÃ³n utilizando los datos procesados y almacenados previamente en la base CLEAN_DATA. Para ello, se entrena un modelo RandomForestClassifier por cada lote (batch_id) presente en la tabla train_data, utilizando un pipeline de preprocesamiento que normaliza las variables numÃ©ricas con StandardScaler y codifica las variables categÃ³ricas con OneHotEncoder. Cada modelo se evalÃºa utilizando mÃ©tricas de desempeÃ±o (precisiÃ³n, recall, f1-score y accuracy) sobre los conjuntos de validaciÃ³n y prueba (val_data y test_data), y sus resultados se registran en la tabla experiments en la base de datos. AdemÃ¡s, se serializa cada modelo por lote y se guarda como artefacto en MLflow. Finalmente, se selecciona automÃ¡ticamente el mejor modelo segÃºn la mÃ©trica val_f1, se guarda con el nombre modelo_entrenado_final.pkl, se registra oficialmente en el Model Registry de MLflow con el nombre mejor_modelo_diabetes, y se promueve al stage de Production para ser consumido desde una API. Todo este proceso es gestionado automÃ¡ticamente por el DAG entrenar_modelo de Airflow.

- **PredicciÃ³n vÃ­a API** 

  Esta etapa corresponde al despliegue del modelo a producciÃ³n mediante una API construida con FastAPI. El archivo expuesto configura una aplicaciÃ³n backend que permite recibir datos de pacientes, realizar predicciones sobre su posible reingreso hospitalario y registrar los resultados en una base de datos. Al iniciar, la API se conecta al servidor de MLflow y al repositorio de artefactos en MinIO para cargar la versiÃ³n del modelo en estado Production, registrado previamente como mejor_modelo_diabetes. La clase InputData define el esquema de entrada validado mediante Pydantic, y el endpoint /predict expone el modelo a solicitudes HTTP POST. Cuando se recibe una solicitud, los datos del paciente son transformados en un DataFrame, enviados al modelo para predecir si el paciente serÃ¡ readmitido, y, si el modelo lo permite, se calcula ademÃ¡s la probabilidad de reingreso. Los resultados, junto con la predicciÃ³n y la marca de tiempo, se almacenan en la tabla predictions del esquema RAW_DATA. Esta soluciÃ³n convierte el modelo en un servicio accesible para integraciones externas o herramientas de visualizaciÃ³n como Streamlit.

  - **API REST con FastAPI**  
      Permite ejecutar cada etapa del flujo mediante endpoints y el servicio estÃ¡ expuesto en el puerto `8080`. 
      http://10.43.101.200:8000/docs

        | Endpoint        | AcciÃ³n                                                   |
        |----------------|----------------------------------------------------------|
        | `/predict`      | Realiza predicciones usando el mejor modelo entrenado    |

    ![Interfaz FastApi](imagenes/FastApi.png)

- **Interfaz grÃ¡fica con Streamlit**  
  la interfaz de usuario desarrollada con Streamlit, diseÃ±ada para interactuar fÃ¡cilmente con el modelo de predicciÃ³n de reingreso hospitalario. Desde el navegador, el usuario puede ingresar manualmente informaciÃ³n clÃ­nica y demogrÃ¡fica del paciente mediante un formulario distribuido en tres columnas que agrupa variables como edad, gÃ©nero, diagnÃ³sticos, visitas mÃ©dicas y caracterÃ­sticas de admisiÃ³n. Al enviar el formulario, los datos son empaquetados en formato JSON y enviados a un endpoint expuesto por la API FastAPI.

  La respuesta del modelo es procesada de inmediato: muestra si el paciente serÃ¡ readmitido (Readmitido o No Readmitido), e incluye la probabilidad estimada de reingreso si el modelo lo permite. Adicionalmente, si la API devuelve informaciÃ³n sobre el nombre y la versiÃ³n del modelo cargado desde MLflow, estos datos tambiÃ©n se muestran en la interfaz para mayor transparencia. Esta aplicaciÃ³n mejora la experiencia del usuario final al proporcionar un acceso claro, interactivo y visualmente amigable al sistema de predicciÃ³n desplegado en producciÃ³n.

  el servicio estÃ¡ expuesto en el puerto `8501`. 
  http://10.43.101.200:8501

  ![Interfaz Streamlit](imagenes/Front_Streamlit.png)

- **Airflow**  

Airflow se encarga de orquestar el flujo completo del proceso y el entrenamiento de modelos. Se ha implementado mediante Docker Compose y estÃ¡ conformado por los siguientes DAGs:

  * cargar_datos: descarga un archivo CSV desde Google Drive y lo inserta en la base de datos RAW_DATA de MySQL.
  * preprocesar_datos: realiza la limpieza y transformaciÃ³n de los datos, y los almacena por lotes en la base CLEAN_DATA.
  * train_model: entrena mÃºltiples modelos por lote utilizando RandomForestClassifier y selecciona automÃ¡ticamente el mejor segÃºn la mÃ©trica val_f1 registrÃ¡ndolo en MLflow.

El servicio de Airflow estÃ¡ expuesto en el puerto 8080, accesible desde la siguiente URL: http://10.43.101.200:8080/home

  ![Airflow](imagenes/Ariflow.png)


- **Minio**  
#


MinIO funciona como un servicio de almacenamiento tipo S3 compatible, utilizado por MLflow para guardar modelos entrenados y otros artefactos.

  * Se ha configurado un bucket llamado mlflows3, donde MLflow almacena automÃ¡ticamente modelos .pkl y archivos asociados a cada experimento.
  * La consola web de MinIO estÃ¡ disponible en el puerto 8083 y permite visualizar los objetos almacenados.

El servicio estÃ¡ disponible en: http://10.43.101.200:8083

  ![Minio](imagenes/minio.png)

- **MlFlow**  

MLflow se encarga de gestionar el seguimiento de experimentos (tracking), almacenamiento de mÃ©tricas, parÃ¡metros, artefactos y versiones de modelos.

  * Se configurÃ³ el contenedor mlflow_server en Docker Compose.
  * Utiliza MySQL como backend-store-uri para guardar la metadata de los experimentos.
  * Emplea MinIO como almacenamiento de artefactos, usando el bucket mlflows3 (--default-artifact-root s3://mlflows3).
  * El servicio de MLflow estÃ¡ expuesto en el puerto 8084 y se puede acceder desde:   http://10.43.101.200:8084
  * Se incluyÃ³ un archivo init.sql para inicializar la base de datos solo cuando el volumen de MySQL estÃ¡ vacÃ­o, asegurando una configuraciÃ³n idempotente del entorno.
    ```
    -- ./mysql-init/init.sql
    CREATE DATABASE IF NOT EXISTS mlflow;
    ```
  ![MlFlow](imagenes/mlflow.png)
---

## ğŸ› ï¸ Puesta en Marcha del Proyecto

Esta secciÃ³n describe los pasos necesarios para levantar todo el ecosistema del sistema de predicciÃ³n de readmisiÃ³n hospitalaria en un entorno local mediante Docker Compose.

### 1. Clonar el Repositorio

```bash
    git clone https://github.com/tu-usuario/proyecto_3.git
    cd proyecto_3
```

### 2 . Verificar Archivos .env y Variables

AsegÃºrese de que las siguientes variables estÃ©n bien definidas en el entorno o dentro del docker-compose.yml:
```bash
    export MLFLOW_S3_ENDPOINT_URL=http://minio:9000
    export AWS_ACCESS_KEY_ID=admin
    export AWS_SECRET_ACCESS_KEY=supersecret
```
### 3. Levantar los Servicios
Ejecuta el siguiente comando para construir y levantar todos los servicios:
```bash
    docker-compose up --build -d
```
Esto desplegarÃ¡ los siguientes contenedores:

  * Airflow (Scheduler, Webserver, Worker, Triggerer, Init)
  * MySQL
  * MinIO
  * MLflow
  * FastAPI (Backend de predicciÃ³n)
  * Streamlit (Frontend para usuarios)

### 4.  Ejecutar los DAGs en Airflow

Para ejecutar el pipeline completo:

- Ingresa a la interfaz de Airflow: http://10.43.101.200:8080
- Activa y ejecuta los DAGs en el siguiente orden:

  * Primero activa y lanza el DAG crear_bases_si_no_existen.
  * Luego, ejecuta el DAG cargar_datos.
  * DespuÃ©s, ejecuta preprocesar_datos.
  * Finalmente, ejecuta entrenar_modelo para entrenar y registrar el mejor modelo.

Esto descargarÃ¡ el dataset, lo insertarÃ¡ en la base RAW_DATA, realizarÃ¡ la transformaciÃ³n y lo almacenarÃ¡ en CLEAN_DATA. Luego entrenarÃ¡ modelos por lote, evaluarÃ¡ y seleccionarÃ¡ el mejor, registrÃ¡ndolo automÃ¡ticamente en MLflow.

### 5. Uso del Sistema

Una vez entrenado el modelo y cargado en MLflow, puedes hacer predicciones desde: Streamlit: desde una interfaz grÃ¡fica en http://localhost:8501, simulando pacientes y visualizando la probabilidad de readmisiÃ³n.


## âœ… Despliegue con kubernetes

