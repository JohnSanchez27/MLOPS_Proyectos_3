# Proyecto 3 - MLOps

Este proyecto implementa una soluci√≥n completa de MLOps que automatiza el proceso de entrenamiento, despliegue y consumo de un modelo de machine learning para predecir la probabilidad de que un paciente sea readmitido en un hospital. Utiliza un enfoque modular basado en contenedores con Docker y herramientas modernas como Apache Airflow, MLflow, MinIO, FastAPI y Streamlit.

  - **Caracter√≠sticas principales**

        - Automatizaci√≥n del flujo de trabajo de datos con Airflow, desde la carga hasta el entrenamiento por lotes.
        - Entrenamiento de modelos por batch y selecci√≥n autom√°tica del mejor modelo con m√©tricas como F1-score.
        - Registro y versionado de modelos en MLflow y almacenamiento de artefactos en MinIO como backend S3.
        - API REST construida con FastAPI que permite servir el modelo en producci√≥n.
        - Interfaz de usuario interactiva desarrollada con Streamlit para simular casos de pacientes y consumir el modelo.
        - Persistencia de predicciones en base de datos MySQL para trazabilidad y an√°lisis posterior.
        - Contenerizaci√≥n de todos los servicios mediante Docker Compose para f√°cil orquestaci√≥n y despliegue local.

---

## üìÅ Estructura del Proyecto

```text
Proyecto_3/
‚îÇ
‚îú‚îÄ‚îÄ app_back/                              # Backend con FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ main.py                            # Endpoints de predicci√≥n conectados a MLflow y MySQL
‚îÇ   ‚îú‚îÄ‚îÄ dockerfile_api.py                  # Dockerfile de la API FastAPI
‚îÇ   ‚îî‚îÄ‚îÄ requirements_api.txt               # Dependencias de FastAPI
‚îÇ
‚îú‚îÄ‚îÄ app_front/                             # Interfaz de usuario con Streamlit
‚îÇ   ‚îú‚îÄ‚îÄ app.py                             # App de Streamlit para ingresar datos y consumir la API
‚îÇ   ‚îú‚îÄ‚îÄ dockerfile_app.py                  # Dockerfile para la interfaz de usuario
‚îÇ   ‚îî‚îÄ‚îÄ requirements_app.txt               # Dependencias de Streamlit
‚îÇ
‚îú‚îÄ‚îÄ connections/                           # Configuraci√≥n de conexi√≥n a bases de datos MySQL
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ mysql_connections.py
‚îÇ
‚îú‚îÄ‚îÄ dags/                                  # Scripts usados por Apache Airflow
‚îÇ   ‚îú‚îÄ‚îÄ carga_datos.py                     # Inserta datos crudos en base RAW
‚îÇ   ‚îú‚îÄ‚îÄ preprocesar_datos.py               # Procesa los datos y los guarda por lotes en CLEAN
‚îÇ   ‚îî‚îÄ‚îÄ train_model.py                     # Entrena modelos, guarda m√©tricas, y registra el mejor en MLflow
‚îÇ
‚îú‚îÄ‚îÄ data/Diabetes/                         # Dataset original
‚îÇ   ‚îî‚îÄ‚îÄ Diabetes.csv
‚îÇ
‚îú‚îÄ‚îÄ mlflow/                                # Configuraci√≥n del servidor MLflow
‚îÇ   ‚îú‚îÄ‚îÄ dockerfile_mlflow                  # Dockerfile para MLflow
‚îÇ   ‚îú‚îÄ‚îÄ init.sql                           # Script de inicializaci√≥n de base de datos para MLflow
‚îÇ   ‚îî‚îÄ‚îÄ requirements_mlflow.txt            # Requerimientos espec√≠ficos para MLflow
‚îÇ
‚îú‚îÄ‚îÄ minio/                                 # Carpeta montada por MinIO para almacenar artefactos de MLflow
‚îÇ   ‚îî‚îÄ‚îÄ (se llena en tiempo de ejecuci√≥n)
‚îÇ
‚îú‚îÄ‚îÄ models/                                # Modelos entrenados y serializados
‚îÇ   ‚îú‚îÄ‚îÄ modelo_entrenado_batch1.pkl
‚îÇ   ‚îú‚îÄ‚îÄ modelo_entrenado_batch2.pkl
‚îÇ   ‚îú‚îÄ‚îÄ modelo_entrenado_batch3.pkl
‚îÇ   ‚îú‚îÄ‚îÄ modelo_entrenado_batch4.pkl
‚îÇ   ‚îú‚îÄ‚îÄ modelo_entrenado_batch5.pkl
‚îÇ   ‚îú‚îÄ‚îÄ modelo_entrenado_batch6.pkl
‚îÇ   ‚îî‚îÄ‚îÄ modelo_entrenado_final.pkl         # Mejor modelo identificado y registrado en MLflow
‚îÇ
‚îú‚îÄ‚îÄ imagenes/                              # Recursos gr√°ficos para documentaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ arquitectura.png
‚îÇ   ‚îú‚îÄ‚îÄ Front_Streamlit.png
‚îÇ   ‚îú‚îÄ‚îÄ Airflow.png
‚îÇ   ‚îú‚îÄ‚îÄ MlFlow.png
‚îÇ   ‚îú‚îÄ‚îÄ Minio.png
‚îÇ   ‚îî‚îÄ‚îÄ Arquitectura del proyecto.png
‚îÇ
‚îú‚îÄ‚îÄ logs/                                  # Logs generados por Airflow y el sistema
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ plugins/                               # (Opcional) Plugins de Airflow si se utilizan
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml                     # Orquestaci√≥n de servicios: Airflow, MLflow, MinIO, MySQL, etc.
‚îú‚îÄ‚îÄ dockerfile                             # Dockerfile base del entorno
‚îú‚îÄ‚îÄ requirements.txt                       # Dependencias globales del proyecto
‚îî‚îÄ‚îÄ README.md                              # Documentaci√≥n del proyecto

```

## ‚úÖ Funcionalidad Actual


- **Carga de datos**  
  La etapa de carga de datos del proyecto se encarga de descargar autom√°ticamente el conjunto de datos original desde una URL externa (espec√≠ficamente desde Google Drive) y almacenarlo en la base de datos RAW_DATA. El archivo solo se descarga si no existe previamente en el directorio local ./data/Diabetes, y se valida que no est√© vac√≠o antes de procesarlo. Si las bases de datos RAW_DATA y CLEAN_DATA no existen, son creadas autom√°ticamente mediante SQLAlchemy. Posteriormente, los datos se insertan en la tabla initial_data del esquema RAW_DATA. Si la tabla no existe, se crea con base en la estructura del archivo CSV; si ya existe, su contenido se limpia antes de insertar los nuevos registros. Todo este flujo es gestionado por dos DAGs de Airflow: uno que verifica y crea las bases de datos (crear_bases_si_no_existen) y otro que realiza la descarga e inserci√≥n del archivo (cargar_datos). Esto garantiza un proceso de ingesta robusto, automatizado y preparado para actualizaciones diarias.

- **Preprocesamiento**

  La etapa de preprocesamiento transforma los datos crudos almacenados en la tabla initial_data de la base RAW_DATA en un conjunto de datos limpio, estructurado y dividido en subconjuntos para entrenamiento, validaci√≥n y prueba. Este proceso incluye la eliminaci√≥n de columnas irrelevantes o con muchos valores nulos, la imputaci√≥n de valores faltantes con la moda de cada categor√≠a, el reemplazo de valores inconsistentes, la transformaci√≥n de edades de rangos a valores num√©ricos y la recodificaci√≥n de variables categ√≥ricas como tipo de admisi√≥n, alta y fuente de ingreso. Adem√°s, se eliminan registros con g√©nero no v√°lido y columnas identificadoras como encounter_id y patient_nbr. Luego, los datos se dividen usando train_test_split y se almacenan en la base CLEAN_DATA en tres tablas: train_data, val_data y test_data. La tabla train_data se divide en lotes identificados con una columna batch_id para permitir un entrenamiento por etapas. Todo este flujo es orquestado por el DAG de Airflow preprocesar_datos, que ejecuta autom√°ticamente estas tareas al ser invocado

  #### C√≥digo:

  ```bash
  def almacenar_en_clean_data(df_train, df_val, df_test, batch_size=15000, random_state=42):
      try:
          df_train = df_train.sample(frac=1, random_state=random_state).reset_index(drop=True)
          total_batches = ceil(len(df_train) / batch_size)

          for batch_number in range(1, total_batches + 1):
              start = (batch_number - 1) * batch_size
              end = batch_number * batch_size
              df_batch = df_train.iloc[start:end].copy()

              if df_batch.empty:
                  continue

              df_batch["batch_id"] = batch_number
              crear_y_reemplazar_si_existe(df_batch, "train_data", cleandatadb_engine)

          crear_y_reemplazar_si_existe(df_val, "val_data", cleandatadb_engine)
          crear_y_reemplazar_si_existe(df_test, "test_data", cleandatadb_engine)

          print("Carga en CLEAN_DATA completada.")
          return total_batches

      except Exception as e:
          print(f"Error al almacenar en CLEAN_DATA: {e}")
          raise e
  ```
- **Entrenamiento del modelo** 

  La etapa de entrenamiento se encarga de construir modelos de predicci√≥n utilizando los datos procesados y almacenados previamente en la base CLEAN_DATA. Para ello, se entrena un modelo RandomForestClassifier por cada lote (batch_id) presente en la tabla train_data, utilizando un pipeline de preprocesamiento que normaliza las variables num√©ricas con StandardScaler y codifica las variables categ√≥ricas con OneHotEncoder. Cada modelo se eval√∫a utilizando m√©tricas de desempe√±o (precisi√≥n, recall, f1-score y accuracy) sobre los conjuntos de validaci√≥n y prueba (val_data y test_data), y sus resultados se registran en la tabla experiments en la base de datos. Adem√°s, se serializa cada modelo por lote y se guarda como artefacto en MLflow. Finalmente, se selecciona autom√°ticamente el mejor modelo seg√∫n la m√©trica val_f1, se guarda con el nombre modelo_entrenado_final.pkl, se registra oficialmente en el Model Registry de MLflow con el nombre mejor_modelo_diabetes, y se promueve al stage de Production para ser consumido desde una API. Todo este proceso es gestionado autom√°ticamente por el DAG entrenar_modelo de Airflow.

- **Predicci√≥n v√≠a API** 

  Esta etapa corresponde al despliegue del modelo a producci√≥n mediante una API construida con FastAPI. El archivo expuesto configura una aplicaci√≥n backend que permite recibir datos de pacientes, realizar predicciones sobre su posible reingreso hospitalario y registrar los resultados en una base de datos. Al iniciar, la API se conecta al servidor de MLflow y al repositorio de artefactos en MinIO para cargar la versi√≥n del modelo en estado Production, registrado previamente como mejor_modelo_diabetes. La clase InputData define el esquema de entrada validado mediante Pydantic, y el endpoint /predict expone el modelo a solicitudes HTTP POST. Cuando se recibe una solicitud, los datos del paciente son transformados en un DataFrame, enviados al modelo para predecir si el paciente ser√° readmitido, y, si el modelo lo permite, se calcula adem√°s la probabilidad de reingreso. Los resultados, junto con la predicci√≥n y la marca de tiempo, se almacenan en la tabla predictions del esquema RAW_DATA. Esta soluci√≥n convierte el modelo en un servicio accesible para integraciones externas o herramientas de visualizaci√≥n como Streamlit.

  - **API REST con FastAPI**  
      Permite ejecutar cada etapa del flujo mediante endpoints y el servicio est√° expuesto en el puerto `8080`. 
      http://10.43.101.200:8000/docs

        | Endpoint        | Acci√≥n                                                   |
        |----------------|----------------------------------------------------------|
        | `/predict`      | Realiza predicciones usando el mejor modelo entrenado    |

    ![Interfaz FastApi](imagenes/FastApi.png)

- **Interfaz gr√°fica con Streamlit**  
  la interfaz de usuario desarrollada con Streamlit, dise√±ada para interactuar f√°cilmente con el modelo de predicci√≥n de reingreso hospitalario. Desde el navegador, el usuario puede ingresar manualmente informaci√≥n cl√≠nica y demogr√°fica del paciente mediante un formulario distribuido en tres columnas que agrupa variables como edad, g√©nero, diagn√≥sticos, visitas m√©dicas y caracter√≠sticas de admisi√≥n. Al enviar el formulario, los datos son empaquetados en formato JSON y enviados a un endpoint expuesto por la API FastAPI.

  La respuesta del modelo es procesada de inmediato: muestra si el paciente ser√° readmitido (Readmitido o No Readmitido), e incluye la probabilidad estimada de reingreso si el modelo lo permite. Adicionalmente, si la API devuelve informaci√≥n sobre el nombre y la versi√≥n del modelo cargado desde MLflow, estos datos tambi√©n se muestran en la interfaz para mayor transparencia. Esta aplicaci√≥n mejora la experiencia del usuario final al proporcionar un acceso claro, interactivo y visualmente amigable al sistema de predicci√≥n desplegado en producci√≥n.

  el servicio est√° expuesto en el puerto `8501`. 
  http://10.43.101.200:8501

  ![Interfaz Streamlit](imagenes/Front_Streamlit.png)

- **Airflow**  

Airflow se encarga de orquestar el flujo completo del proceso y el entrenamiento de modelos. Se ha implementado mediante Docker Compose y est√° conformado por los siguientes DAGs:

  * cargar_datos: descarga un archivo CSV desde Google Drive y lo inserta en la base de datos RAW_DATA de MySQL.
  * preprocesar_datos: realiza la limpieza y transformaci√≥n de los datos, y los almacena por lotes en la base CLEAN_DATA.
  * train_model: entrena m√∫ltiples modelos por lote utilizando RandomForestClassifier y selecciona autom√°ticamente el mejor seg√∫n la m√©trica val_f1 registr√°ndolo en MLflow.

El servicio de Airflow est√° expuesto en el puerto 8080, accesible desde la siguiente URL: http://10.43.101.200:8080/home

  ![Airflow](imagenes/Ariflow.png)


- **Minio**  
#


MinIO funciona como un servicio de almacenamiento tipo S3 compatible, utilizado por MLflow para guardar modelos entrenados y otros artefactos.

  * Se ha configurado un bucket llamado mlflows3, donde MLflow almacena autom√°ticamente modelos .pkl y archivos asociados a cada experimento.
  * La consola web de MinIO est√° disponible en el puerto 8083 y permite visualizar los objetos almacenados.

El servicio est√° disponible en: http://10.43.101.200:8083

  ![Minio](imagenes/minio.png)

- **MlFlow**  

MLflow se encarga de gestionar el seguimiento de experimentos (tracking), almacenamiento de m√©tricas, par√°metros, artefactos y versiones de modelos.

  * Se configur√≥ el contenedor mlflow_server en Docker Compose.
  * Utiliza MySQL como backend-store-uri para guardar la metadata de los experimentos.
  * Emplea MinIO como almacenamiento de artefactos, usando el bucket mlflows3 (--default-artifact-root s3://mlflows3).
  * El servicio de MLflow est√° expuesto en el puerto 8084 y se puede acceder desde:   http://10.43.101.200:8084
  * Se incluy√≥ un archivo init.sql para inicializar la base de datos solo cuando el volumen de MySQL est√° vac√≠o, asegurando una configuraci√≥n idempotente del entorno.
    ```
    -- ./mysql-init/init.sql
    CREATE DATABASE IF NOT EXISTS mlflow;
    ```
  ![MlFlow](imagenes/mlflow.png)
---

## üõ†Ô∏è Puesta en Marcha del Proyecto

Esta secci√≥n describe los pasos necesarios para levantar todo el ecosistema del sistema de predicci√≥n de readmisi√≥n hospitalaria en un entorno local mediante Docker Compose.

### 1. Clonar el Repositorio

```bash
    git clone https://github.com/tu-usuario/proyecto_3.git
    cd proyecto_3
```

### 2 . Verificar Archivos .env y Variables

Aseg√∫rese de que las siguientes variables est√©n bien definidas en el entorno o dentro del docker-compose.yml:
```bash
    export MLFLOW_S3_ENDPOINT_URL=http://minio:9000
    export AWS_ACCESS_KEY_ID=admin
    export AWS_SECRET_ACCESS_KEY=supersecret
```
### 3. Levantar los Servicios
Ejecuta el siguiente comando para construir y levantar todos los servicios:
```bash
    docker-compose up --build -d
```
Esto desplegar√° los siguientes contenedores:

  * Airflow (Scheduler, Webserver, Worker, Triggerer, Init)
  * MySQL
  * MinIO
  * MLflow
  * FastAPI (Backend de predicci√≥n)
  * Streamlit (Frontend para usuarios)

### 4.  Ejecutar los DAGs en Airflow

Para ejecutar el pipeline completo:

- Ingresa a la interfaz de Airflow: http://10.43.101.200:8080
- Activa y ejecuta los DAGs en el siguiente orden:

  * Primero activa y lanza el DAG crear_bases_si_no_existen.
  * Luego, ejecuta el DAG cargar_datos.
  * Despu√©s, ejecuta preprocesar_datos.
  * Finalmente, ejecuta entrenar_modelo para entrenar y registrar el mejor modelo.

Esto descargar√° el dataset, lo insertar√° en la base RAW_DATA, realizar√° la transformaci√≥n y lo almacenar√° en CLEAN_DATA. Luego entrenar√° modelos por lote, evaluar√° y seleccionar√° el mejor, registr√°ndolo autom√°ticamente en MLflow.

### 5. Uso del Sistema

Una vez entrenado el modelo y cargado en MLflow, puedes hacer predicciones desde: Streamlit: desde una interfaz gr√°fica en http://localhost:8501, simulando pacientes y visualizando la probabilidad de readmisi√≥n.


## ‚úÖ Despliegue con kubernetes

A continuaci√≥n, se detallar√° el proceso paso a paso para la implementaci√≥n de la infraestructura del proyecto utilizando Kubernetes. Es importante destacar que, en este caso, se opt√≥ por una arquitectura h√≠brida, ya que no todos los servicios fueron desplegados bajo Kubernetes. En particular, se utilizaron Kubernetes √∫nicamente para desplegar los servicios de FastAPI y Streamlit.

Inicialmente, la intenci√≥n era montar los servicios de MiniO y MySQL tambi√©n bajo Kubernetes. Sin embargo, durante el proceso de configuraci√≥n y despliegue, se encontraron diversos desaf√≠os t√©cnicos que impidieron exponer estos servicios de manera adecuada dentro del entorno de Kubernetes. A pesar de los esfuerzos por resolver estos problemas, no se logr√≥ una configuraci√≥n estable que permitiera la exposici√≥n correcta de los servicios mencionados. Por tal razon se opto por un modelo hibrido donde los demas servicios fueron orquestados con docker compose (Airflow, MlFlow, Minio y  MySQL) 

Antes de que nada se creron dos imagenes en Docker Hub, una imagen para FastAPI y otra para Streamlit como se muestran en las siguientes imagenes:

![image](https://github.com/user-attachments/assets/7f320c72-7c76-4f98-a231-4120dc9c454a)



